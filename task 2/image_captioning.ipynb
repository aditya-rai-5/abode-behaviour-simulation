{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-01T04:49:45.193291Z",
     "iopub.status.busy": "2025-11-01T04:49:45.193052Z",
     "iopub.status.idle": "2025-11-01T04:49:46.682123Z",
     "shell.execute_reply": "2025-11-01T04:49:46.681359Z",
     "shell.execute_reply.started": "2025-11-01T04:49:45.193264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T04:49:46.683048Z",
     "iopub.status.busy": "2025-11-01T04:49:46.682781Z",
     "iopub.status.idle": "2025-11-01T04:51:03.408454Z",
     "shell.execute_reply": "2025-11-01T04:51:03.407396Z",
     "shell.execute_reply.started": "2025-11-01T04:49:46.683031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T04:51:03.410708Z",
     "iopub.status.busy": "2025-11-01T04:51:03.410446Z",
     "iopub.status.idle": "2025-11-01T04:51:08.849746Z",
     "shell.execute_reply": "2025-11-01T04:51:08.849008Z",
     "shell.execute_reply.started": "2025-11-01T04:51:03.410685Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.48.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T04:51:08.850971Z",
     "iopub.status.busy": "2025-11-01T04:51:08.850738Z",
     "iopub.status.idle": "2025-11-01T04:52:16.068299Z",
     "shell.execute_reply": "2025-11-01T04:52:16.067455Z",
     "shell.execute_reply.started": "2025-11-01T04:51:08.850940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 04:51:19.041595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761972679.272039      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761972679.333126      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1817f03ce18f4b54aa1c98cebc0b1a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfa1d59935f40d89c32089233e8682f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787d4c762cf94b2aa56fb20c7761a71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db48cf79d47941d782cf1327375670a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43020204cc5445fbb0d00639a892f488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a90105a7db45a6a93c0f15f5ccd81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5326828e15194da090a667ffd3453d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84256b772db74d50b838a52b5a8ba087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee262939da34ce0a41423374a2132d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65d5e61bba045048bd7de7e61667fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b7b30a1d804554a4ee4f0c122e041c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93443b130c52405997dd3681453af016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b1304fb7af42cd85a7d9989583c45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration, BitsAndBytesConfig\n",
    "\n",
    "model_path = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4'\n",
    ")\n",
    "\n",
    "model =Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T04:52:16.069834Z",
     "iopub.status.busy": "2025-11-01T04:52:16.069201Z",
     "iopub.status.idle": "2025-11-01T04:52:16.079468Z",
     "shell.execute_reply": "2025-11-01T04:52:16.078762Z",
     "shell.execute_reply.started": "2025-11-01T04:52:16.069813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def caption_images_batch(image_files_list, prompt):\n",
    "    \"\"\"\n",
    "    Generates captions for a BATCH of image files (URLs or local paths)\n",
    "    using the loaded Qwen-VL model and a single shared prompt.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    max_size = (512, 512) \n",
    "    \n",
    "    for image_file in image_files_list:\n",
    "        try:\n",
    "            if image_file.startswith('http') or image_file.startswith('https'):\n",
    "                response = requests.get(image_file, timeout=10) \n",
    "                current_image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "            else:\n",
    "                current_image = Image.open(image_file).convert('RGB')\n",
    "            \n",
    "            current_image.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
    "            images.append(current_image)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_file}: {e}\")\n",
    "            images.append(None) \n",
    "\n",
    "    \n",
    "    valid_images = [img for img in images if img is not None]\n",
    "    \n",
    "    if not valid_images:\n",
    "        return [\"Error: No valid images in batch\"] * len(image_files_list)\n",
    "\n",
    "    conversations = []\n",
    "    for _ in valid_images:\n",
    "        conversations.append([\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": prompt}\n",
    "                ]\n",
    "            }\n",
    "        ])\n",
    "\n",
    "    text_prompts = processor.apply_chat_template(conversations, add_generation_prompt=True, tokenize=False)\n",
    "    \n",
    "    inputs = processor(\n",
    "        text=text_prompts,\n",
    "        images=valid_images,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True \n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        output_ids = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=512,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    input_token_len = inputs['input_ids'].shape[1]\n",
    "    generated_ids = output_ids[:, input_token_len:]\n",
    "    responses = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    cleaned_responses = [resp.strip() for resp in responses]\n",
    "    \n",
    "    final_output = []\n",
    "    resp_index = 0\n",
    "    for img in images:\n",
    "        if img is None:\n",
    "            final_output.append(\"Error: Image load failed\")\n",
    "        else:\n",
    "            final_output.append(cleaned_responses[resp_index])\n",
    "            resp_index += 1\n",
    "            \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T06:37:20.988167Z",
     "iopub.status.busy": "2025-11-01T06:37:20.987909Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from {YOUR_CSV_FILE}...\n",
      "Dataset loaded. Total rows: 1000\n",
      "Starting processing in batches of 36...\n",
      "Processing Batch 1/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/EXaIreiXsAAKRuu?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a2e20e1b0>\n",
      "Error loading image https://pbs.twimg.com/media/ElB41cOW0AETKcX?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f49fabc7dd0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 finished in 81.31 seconds.\n",
      "Saving intermediate results to /kaggle/working/generated_captions_test.csv...\n",
      "Processing Batch 2/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/EA47wp5XsAALqO8?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a2e20e1b0>\n",
      "Error loading image https://pbs.twimg.com/media/DmkhTgJWwAAEts7?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a2e1c2f70>\n",
      "Error loading image https://pbs.twimg.com/media/EWLW38GU0AAOLyA?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a2e20d940>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 finished in 96.71 seconds.\n",
      "Processing Batch 3/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/ext_tw_video_thumb/1152653784419622912/pu/img/bn1si8rNAaZAAFJo.jpg: cannot identify image file <_io.BytesIO object at 0x7f4a3ce932e0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3 finished in 82.97 seconds.\n",
      "Processing Batch 4/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/DTRSzQhXcAAE2nV?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a2e1c2f70>\n",
      "Error loading image https://pbs.twimg.com/media/D5VXQhzXoAAszE8?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a2e1c2f70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4 finished in 98.52 seconds.\n",
      "Processing Batch 5/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/DfbBnNCXcAYVIBd?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce52840>\n",
      "Error loading image https://pbs.twimg.com/media/EXhwK-xXkAA-Cm8?format=png&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a2c2b7c90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5 finished in 81.74 seconds.\n",
      "Processing Batch 6/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/EQhm8MFWoAAvyqc?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce7f650>\n",
      "Error loading image https://pbs.twimg.com/amplify_video_thumb/1109597951742103553/img/YMTrUGorpRvMBTcH.jpg: cannot identify image file <_io.BytesIO object at 0x7f4a3ce1a390>\n",
      "Error loading image https://pbs.twimg.com/ext_tw_video_thumb/1141017779702763527/pu/img/5Ov9y-XmMudfszwx.jpg: cannot identify image file <_io.BytesIO object at 0x7f4a3ce7c950>\n",
      "Error loading image https://pbs.twimg.com/media/DstwARLW0AIBLT3?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce7f650>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6 finished in 78.52 seconds.\n",
      "Saving intermediate results to /kaggle/working/generated_captions_test.csv...\n",
      "Processing Batch 7/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/DhYzbSJWsAA79js?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3c321d00>\n",
      "Error loading image https://pbs.twimg.com/media/ElP0RmsU8AAmzKT?format=png&name=small: cannot identify image file <_io.BytesIO object at 0x7f49fab2d300>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7 finished in 95.23 seconds.\n",
      "Processing Batch 8/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/EFaQzozWkAADYqt?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a2e25b010>\n",
      "Error loading image https://pbs.twimg.com/media/D3yA6rhXoAECU1H?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce911c0>\n",
      "Error loading image https://pbs.twimg.com/media/DpIJVviWkAApq2P?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f49faac7880>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8 finished in 83.28 seconds.\n",
      "Processing Batch 9/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/DtGzWWmXQAUb9-d?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce9af20>\n",
      "Error loading image https://pbs.twimg.com/media/DU9cKpVXcAIKf_M?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce1ac50>\n",
      "Error loading image https://pbs.twimg.com/media/EllIOYFXEAMibuY?format=png&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce93010>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9 finished in 94.00 seconds.\n",
      "Processing Batch 10/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/D1726MdU8AAz67A?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3c3fdbc0>\n",
      "Error loading image https://pbs.twimg.com/media/DtC2liZXcAAk8PK?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce91b20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10 finished in 101.64 seconds.\n",
      "Processing Batch 11/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/D5q8uDmXkAEl_qK?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce93e20>\n",
      "Error loading image https://pbs.twimg.com/media/EUp1dahUcAAd_nA?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4ba38c3c90>\n",
      "Error loading image https://pbs.twimg.com/ext_tw_video_thumb/1172699880873005056/pu/img/kGc2o8tFCLUzuN1n.jpg: cannot identify image file <_io.BytesIO object at 0x7f4a3e7dd490>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11 finished in 97.30 seconds.\n",
      "Saving intermediate results to /kaggle/working/generated_captions_test.csv...\n",
      "Processing Batch 12/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/EETTKm0UUAEQN1U?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a2e32afc0>\n",
      "Error loading image https://pbs.twimg.com/media/EUfzh-zU0AAtCIo?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3c38c900>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12 finished in 76.75 seconds.\n",
      "Processing Batch 13/28 (Found 36 valid images)...\n",
      "Error loading image https://pbs.twimg.com/media/D8YW6XOWwAAWoYe?format=png&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3e7c89f0>\n",
      "Error loading image https://pbs.twimg.com/media/EBjiH6AWkAUkjkn?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce93ba0>\n",
      "Error loading image https://pbs.twimg.com/media/EpNG-yOXEAMl8_5?format=jpg&name=small: cannot identify image file <_io.BytesIO object at 0x7f4a3ce3f4c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 36\n",
    "YOUR_CSV_FILE = '/kaggle/input/kbfkwebfiwe/test_dataset.csv'\n",
    "OUTPUT_CSV_FILE = '/kaggle/working/generated_captions_test.csv'\n",
    "MEDIA_COLUMN_NAME = 'media_url'\n",
    "NO_MEDIA_STRING = \"no media found\"\n",
    "\n",
    "text_prompt=\"\"\"\n",
    "Describe everything visible in the image with maximum objective detail, including all objects, environment, people, text, vehicle features, materials, lighting, spatial layout, textures, and reflections without guessing unseen context or intent. give \"\"\"\n",
    "\n",
    "print(\"Loading dataset from {YOUR_CSV_FILE}...\")\n",
    "try:\n",
    "    df = pd.read_csv(YOUR_CSV_FILE,nrows=1000)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {YOUR_CSV_FILE}\")\n",
    "\n",
    "df['generated_caption'] = None\n",
    "print(f\"Dataset loaded. Total rows: {len(df)}\")\n",
    "\n",
    "total_batches = math.ceil(len(df) / BATCH_SIZE)\n",
    "total_start_time = time.time()\n",
    "\n",
    "print(f\"Starting processing in batches of {BATCH_SIZE}...\")\n",
    "\n",
    "for i in range(0, len(df), BATCH_SIZE):\n",
    "    batch_start_time = time.time()\n",
    "    \n",
    "    batch_df = df.iloc[i : i + BATCH_SIZE]\n",
    "    \n",
    "    urls_to_process = []\n",
    "    valid_indices = []\n",
    "\n",
    "    for index, row in batch_df.iterrows():\n",
    "        media_data = str(row[\"media_url\"])\n",
    "        \n",
    "        if NO_MEDIA_STRING not in media_data.lower() and pd.notna(media_data):\n",
    "            extracted_url = media_data\n",
    "            if extracted_url:\n",
    "                urls_to_process.append(extracted_url)\n",
    "                valid_indices.append(index) # यह इंडेक्स (e.g., 20, 21, 23, 27...)\n",
    "            else:\n",
    "                df.at[index, 'generated_caption'] = \"Error: URL extraction failed\"\n",
    "        else:\n",
    "            df.at[index, 'generated_caption'] = \"\"\n",
    "\n",
    "    if urls_to_process:\n",
    "        print(f\"Processing Batch {i//BATCH_SIZE + 1}/{total_batches} (Found {len(urls_to_process)} valid images)...\")\n",
    "        \n",
    "        batch_captions = caption_images_batch(urls_to_process, text_prompt)\n",
    "\n",
    "        for j, caption in enumerate(batch_captions):\n",
    "            original_index = valid_indices[j]\n",
    "            df.at[original_index, 'generated_caption'] = caption\n",
    "    else:\n",
    "        print(f\"Skipping Batch {i//BATCH_SIZE + 1}/{total_batches} (No valid images found)\")\n",
    "\n",
    "    batch_end_time = time.time()\n",
    "    print(f\"Batch {i//BATCH_SIZE + 1} finished in {batch_end_time - batch_start_time:.2f} seconds.\")\n",
    "\n",
    "    if (i // BATCH_SIZE) % 5 == 0:\n",
    "        print(f\"Saving intermediate results to {OUTPUT_CSV_FILE}...\")\n",
    "        df.to_csv(OUTPUT_CSV_FILE, index=False)\n",
    "\n",
    "\n",
    "total_end_time = time.time()\n",
    "print(\"\\n--- Processing Complete ---\")\n",
    "print(f\"Total time taken: {(total_end_time - total_start_time) / 60:.2f} minutes.\")\n",
    "print(f\"Saving final results to {OUTPUT_CSV_FILE}...\")\n",
    "df.to_csv(OUTPUT_CSV_FILE, index=False)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8617779,
     "sourceId": 13566454,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8623368,
     "sourceId": 13574437,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
