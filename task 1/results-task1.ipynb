{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==============================================================================\n# CELL 1: SETUP AND LOAD YOUR STAGE 1 CLASSIFIER\n# ==============================================================================\nprint(\"Installing all necessary libraries...\")\n!pip install transformers datasets scikit-learn pandas openpyxl lightgbm vaderSentiment --quiet\n\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom google.colab import drive\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import Dataset\nimport torch\nimport gc\nimport re\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\n# --- Mount Google Drive ---\nprint(\"\\nMounting Google Drive...\")\ndrive.mount('/content/drive', force_remount=True)\n\n# --- 1. LOAD STAGE 1 CLASSIFIER (Your Winning RoBERTa Model) ---\nSTAGE_1_PATH = \"/content/drive/MyDrive/my_best_ROBERTA_model3\"\nprint(f\"Loading your winning classifier from: {STAGE_1_PATH}...\")\ntry:\n    s1_tokenizer = AutoTokenizer.from_pretrained(STAGE_1_PATH)\n    s1_model = AutoModelForSequenceClassification.from_pretrained(STAGE_1_PATH).to(device)\n    print(\"Stage 1 Classifier loaded successfully.\")\nexcept Exception as e:\n    print(f\"*** FATAL ERROR: Could not load your model. {e} ***\")\n    print(\"Please check the folder path and contents.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GD4Ys4kYjFI2","outputId":"48d530c7-564c-4b12-d933-efdbeaca8d3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing all necessary libraries...\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing device: cuda\n","\n","Mounting Google Drive...\n","Mounted at /content/drive\n","Loading your winning classifier from: /content/drive/MyDrive/my_best_ROBERTA_model3...\n","Stage 1 Classifier loaded successfully.\n"]}],"execution_count":null},{"cell_type":"code","source":"# ==============================================================================\n# CELL 2: LOAD DATA & GENERATE ALL FEATURES FOR STAGE 2\n# ==============================================================================\n\n# --- 1. Load Full 300k Dataset ---\ndef load_data_from_drive(filename=\"Copy of behaviour_simulation_train.xlsx\"):\n    file_path = f'/content/drive/MyDrive/{filename}'\n    try:\n        print(f\"\\nAttempting to load full training data from: {file_path}\")\n        df = pd.read_excel(file_path)\n        print(f\"Data loaded successfully! Shape: {df.shape}\")\n        df.rename(columns={'dates': 'date', 'inferred company': 'company'}, inplace=True)\n        df['date'] = pd.to_datetime(df['date'])\n        return df\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None\n\nfull_train_df = load_data_from_drive()\n\n# --- 2. Define Helper Functions ---\ndef format_input_text(row):\n    tweet_text = str(row['content']).strip()\n    company = str(row['company']).strip()\n    hour = row['date'].hour\n    day = row['date'].day_name()\n    has_media = \"yes\" if pd.notna(row['media']) else \"no\"\n    return f\"Brand: {company} | Day: {day} | Hour: {hour} | Media: {has_media} | Tweet: {tweet_text}\"\n\ndef create_manual_features(df):\n    print(\"Generating manual features (text length, time, sentiment)...\")\n    temp_df = df.copy()\n    analyzer = SentimentIntensityAnalyzer()\n\n    temp_df['content'] = temp_df['content'].fillna('').astype(str)\n    temp_df['text_len'] = temp_df['content'].apply(len)\n    temp_df['word_count'] = temp_df['content'].apply(lambda x: len(x.split()))\n\n    # We use .astype('category') to prevent the ValueError\n    temp_df['hour'] = temp_df['date'].dt.hour.astype('category')\n    temp_df['dayofweek'] = temp_df['date'].dt.dayofweek.astype('category')\n    temp_df['has_media'] = temp_df['media'].notna().astype('category')\n    temp_df['company_cat'] = temp_df['company'].astype('category')\n    temp_df['username_cat'] = temp_df['username'].astype('category')\n\n    temp_df['sentiment'] = temp_df['content'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n\n    print(\"Manual features complete.\")\n    return temp_df\n\n# --- 3. Generate Transformer Probabilities (This is the slow part) ---\nprint(\"Generating formatted text for Transformer...\")\nfull_train_df['text'] = full_train_df.apply(format_input_text, axis=1)\n\n# Convert to a 'Dataset' to use the fast .map() function\nhf_dataset = Dataset.from_pandas(full_train_df[['text']])\n\ndef predict_probabilities(batch):\n    inputs = s1_tokenizer(batch['text'], return_tensors=\"pt\", padding=True, truncation=True, max_length=256).to(device)\n    with torch.no_grad():\n        logits = s1_model(**inputs).logits\n    probabilities = torch.softmax(logits, dim=1).cpu().numpy()\n    return {\n        'prob_low': probabilities[:, 0],\n        'prob_medium': probabilities[:, 1],\n        'prob_high': probabilities[:, 2],\n        'prob_viral': probabilities[:, 3],\n    }\n\nprint(f\"Running Stage 1 Classifier to generate probabilities for {len(full_train_df)} tweets...\")\nprint(\"(This will take 20-30 minutes, please be patient!)\")\nprob_dataset = hf_dataset.map(predict_probabilities, batched=True, batch_size=64)\nprint(\"Probability generation complete.\")\n\n# --- 4. Combine All Features into X and y ---\nprint(\"Combining all features...\")\nprob_df = prob_dataset.to_pandas()\nmanual_features_df = create_manual_features(full_train_df)\n\nmanual_feature_cols = ['text_len', 'word_count', 'hour', 'dayofweek', 'sentiment', 'has_media', 'company_cat', 'username_cat']\nprob_feature_cols = ['prob_low', 'prob_medium', 'prob_high', 'prob_viral']\n\nX = pd.concat([manual_features_df[manual_feature_cols], prob_df[prob_feature_cols]], axis=1)\ny = np.log1p(full_train_df['likes']) # Our target is log(likes)\n\n# We also need the original text and likes for the \"highlight reel\"\noriginal_text = manual_features_df['content']\noriginal_likes = full_train_df['likes']\n\nprint(f\"Final training dataset 'X' created with shape: {X.shape}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240,"referenced_widgets":["a922d62ded7d45778303a0b0474f93be","bdbea884506f4fdb87f43e6230e6ffad","644622910101452d9015920b0c543db3","4fe7f314bab742aaa12275354a904214","ea921943692c4e159ab6b6c337872fe5","ccb079a6f5164886ad8c2feee9373960","a45d68bd497d440fb6b35f2cacc88d20","7d4e5acc7ce247859190e63304c25f1c","2ff2240829d6487da179635cad93bef9","cc0f999476714ea5a6894d88997e59c7","b34ef953e43a4ebdabbb913a8feffc7f"]},"id":"GmudhMrQr6sY","outputId":"e8f4834d-cd5d-4f68-d032-075168158ce9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Attempting to load full training data from: /content/drive/MyDrive/Copy of behaviour_simulation_train.xlsx\n","Data loaded successfully! Shape: (300000, 7)\n","Generating formatted text for Transformer...\n","Running Stage 1 Classifier to generate probabilities for 300000 tweets...\n","(This will take 20-30 minutes, please be patient!)\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/300000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a922d62ded7d45778303a0b0474f93be"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Probability generation complete.\n","Combining all features...\n","Generating manual features (text length, time, sentiment)...\n","Manual features complete.\n","Final training dataset 'X' created with shape: (300000, 12)\n"]}],"execution_count":null},{"cell_type":"code","source":"# ==============================================================================\n# CELL 3: TRAIN STAGE 2 REGRESSOR (LightGBM)\n# ==============================================================================\n\nprint(\"Creating the identical 80/20 split for training and validation...\")\n# We must create a mask that perfectly matches the 60,000 samples\n# your classifier was validated on.\n# We re-create the split from the 300k data to get the *indices*.\n# stratify=full_train_df['label'] is not needed here as we use random_state\nindices = np.arange(len(full_train_df))\ntrain_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n\nprint(f\"Split complete. Training on {len(train_indices)}, validating on {len(val_indices)}.\")\n\n# Create the final train/val sets for LightGBM\nX_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\nX_val, y_val = X.iloc[val_indices], y.iloc[val_indices]\n\n# Also grab the original text/likes for the validation set\nval_text = original_text.iloc[val_indices]\nval_actual_likes = original_likes.iloc[val_indices]\n\n\n# --- Train the LightGBM Model ---\nprint(\"\\nTraining Stage 2 LightGBM Regressor... (This will take 5-10 minutes)\")\ncategorical_features = ['has_media', 'company_cat', 'username_cat', 'dayofweek', 'hour']\n\nlgbm_regressor = lgb.LGBMRegressor(\n    objective='regression_l1',\n    metric='rmse',\n    n_estimators=1000,\n    learning_rate=0.05,\n    num_leaves=31,\n    random_state=42,\n    n_jobs=-1\n)\n\nlgbm_regressor.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    eval_metric='rmse',\n    callbacks=[lgb.early_stopping(100)],\n    categorical_feature=categorical_features\n)\n\nprint(\"\\n--- Stage 2 Model Evaluation ---\")\nval_preds_log = lgbm_regressor.predict(X_val)\nval_preds_real = np.expm1(val_preds_log)\nval_preds_real[val_preds_real < 0] = 0\n\nfinal_rmse = np.sqrt(mean_squared_error(val_actual_likes, val_preds_real))\nprint(f\"Final Model RMSE (on real 'likes' scale): {final_rmse:.4f}\")\n\nprint(\"\\nCreating results DataFrame for 'Highlight Reel'...\")\n# --- Create the \"Highlight Reel\" DataFrame ---\ndf_results = pd.DataFrame({\n    'Tweet Text': val_text,\n    'Actual Likes': val_actual_likes,\n    'Predicted Likes': val_preds_real.astype(int)\n})\n\n# This is the key column for finding the \"best\" predictions\ndf_results['Error'] = df_results['Actual Likes'] - df_results['Predicted Likes']\ndf_results['Absolute Error'] = df_results['Error'].abs()\n\nprint(\"Results DataFrame created.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDx4hMMwr9FQ","outputId":"43d98ac0-1952-45c7-ca20-b7f5498f25a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating the identical 80/20 split for training and validation...\n","Split complete. Training on 240000, validating on 60000.\n","\n","Training Stage 2 LightGBM Regressor... (This will take 5-10 minutes)\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051984 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3252\n","[LightGBM] [Info] Number of data points in the train set: 240000, number of used features: 11\n","[LightGBM] [Info] Start training from score 4.343805\n","Training until validation scores don't improve for 100 rounds\n","Early stopping, best iteration is:\n","[446]\tvalid_0's rmse: 0.78147\n","\n","--- Stage 2 Model Evaluation ---\n","Final Model RMSE (on real 'likes' scale): 4039.1569\n","\n","Creating results DataFrame for 'Highlight Reel'...\n","Results DataFrame created.\n"]}],"execution_count":null},{"cell_type":"code","source":"# ==============================================================================\n# CELL 4: THE \"HIGHLIGHT REEL\" (BEST PREDICTIONS)\n# ==============================================================================\n\n# Set pandas to show full tweet text\npd.set_option('display.max_colwidth', None)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"     HIGHLIGHT REEL: THE 20 BEST PREDICTIONS\")\nprint(\"  (Sorted by smallest absolute error, highest likes first)\")\nprint(\"=\"*50)\n\n# Sort by smallest error, but show the most popular tweets first\nbest_predictions = df_results.sort_values(by=['Absolute Error', 'Actual Likes'], ascending=[True, False])\n\nprint(best_predictions.head(20))\n\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"     'ALMOST' REEL: THE 20 MOST IMPRESSIVE 'NEAR MISSES'\")\nprint(\"  (For 'Viral' tweets where the prediction was also 'Viral' or 'High')\")\nprint(\"=\"*50)\n\n# Filter for *actual* viral tweets, then sort by error\nimpressive_misses = df_results[df_results['Actual Likes'] > 10000].sort_values(by='Absolute Error')\n\nprint(impressive_misses.head(20))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwgM7zatslrA","outputId":"87e36f34-d33f-47d1-f3e3-5b34e433eeff"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","     HIGHLIGHT REEL: THE 20 BEST PREDICTIONS\n","  (Sorted by smallest absolute error, highest likes first)\n","==================================================\n","                                                                                                                                                                                                                                                                                                      Tweet Text  \\\n","175545                                                                                                                                                               Britain's Princess Charlotte, youngest child of the Duke and Duchess of Cambridge, started nursery school on Monday <hyperlink> <hyperlink>   \n","57495                                                                                                        The US surgeon general calls on healthy Americans to donate blood. The Red Cross is facing a \"severe\" shortage due to blood drive cancellations in response to coronavirus. <hyperlink> <hyperlink>   \n","255042                                                                                                                            Facebook has taken down 652 pages, accounts and groups it says were part of a coordinated disinformation campaign. Some originated in Iran and Russia. <hyperlink> <hyperlink>   \n","76472                                                                                                                                                               A court filing from special counsel Robert Mueller's office reveals new bank fraud allegations against Paul Manafort <hyperlink> <hyperlink>   \n","280748                                                                                                                                                                                               This Ivanka Trump answer is exactly why nepotism laws exist | Analysis by <mention> <hyperlink> <hyperlink>   \n","287509                       \"The most important thing is that you become good persons. This is the best advice we can give you\", said <mention> to the 2019 RNA graduates. üë©üèª‚Äçüéì\\n\\nEste martes la ceremonia de graduaci√≥n de 2020 ser√° diferente... ¬°Pero intentaremos que sea igual de especial! üòä <hyperlink>   \n","213527                                                                                                                                                                                                                                                         The 04 phases of a goal celebration üòÇ <hyperlink>   \n","282221                                                                                                                                                                                                                                        Big-hearted thanks to those who keep the world running <hyperlink>   \n","24286                                                                                                                                                                                                     Can't wait for 2020. Tix to <mention>'s #chillaxificationtour are on sale now. <hyperlink> <hyperlink>   \n","44748                                                                                                                          Our Red Rig this week comes by way of Croatia courtesy of #AMDRedTeam member palinker! With a brand-new case and some choice LEDs, this system absolutely bleeds red. <hyperlink>   \n","126333                 Discover one-of-a-kind viewing experience with 6‚Äô‚ÄôsAMOLED #InfinityDisplay of the new #GalaxyJ8. Buy now to get one-time screen replacement and INR 2000.00 cashback on Paytm Mall or ICICI Bank credit/debit cards. Know More: <hyperlink> #ToInfinityAndMore T&amp;C apply. <hyperlink>   \n","29722                                                   Congrats to <mention> freshman QB Alan Bowman, this week's #ManningAward Quarterback of the Week! He threw for a <mention> freshman record 605 yards with five touchdowns in a 63-49 victory over previously undefeated Houston. <hyperlink> <hyperlink>   \n","284375                                                                Enjoy larger-than-life visuals on a screen that fits in any home. The Serif boasts nano-sized quantum dots that work to produce 100% real colour so you can enjoy vivid visuals, even in the darkest scenes and coziest rooms. <hyperlink>   \n","43978                                                                                                                                                                           A 100-person strong contingent of medical workers is arriving at Grand Army Plaza after marching from SUNY Downstate <hyperlink>   \n","265665                                                                                                                                                                                                                                                    Looks like <mention> had something to say. <hyperlink>   \n","175686  The #SugarBowl name comes from the site where the game was originally played near Audubon Park, land once owned by Etienne de Bore‚Äô, who successfully crystallized sugar in 1795. The crop &amp; industry made Louisiana the nation‚Äôs ‚Äúsugar bowl‚Äù and the rest is state and sports history! <hyperlink>   \n","23443                         Armed with the Qualcomm Snapdragon 865 Plus, the #ROGPhone3 operates at an insane clock speed of 3.1GHz! Get yours on <mention> <hyperlink> to always be ahead of the curve when it comes to in-game domination or multitasking. #WorshippedByGamers #LovedByTechGurus <hyperlink>   \n","74171               Hey #sciencetwitter I have another fun question for you guys. If you guys had to pick an adaptive trait to have out of all the animals in the world what would it be? Personally for myself I would pick chromatophore cells so I can adjust to my surroundings whenever I want! <hyperlink>   \n","125831               COMPETITION TIME\\n\\nTo celebrate the launch of the ALX range, we're giving away a set to a lucky winner! How to win:\\n\\nüéØRT this tweet\\n\\nüéØComment your favourite  ALX barrel shape - check them out here: <hyperlink>\\n\\nüéØFollow <mention> \\n\\n#TargetDarts #Darts #StepBeyond <hyperlink>   \n","158975                                                                                                                                                                                                                                                                           That #FridayFeeling <hyperlink>   \n","\n","        Actual Likes  Predicted Likes  Error  Absolute Error  \n","175545          1276             1276      0               0  \n","57495            901              901      0               0  \n","255042           799              799      0               0  \n","76472            733              733      0               0  \n","280748           726              726      0               0  \n","287509           584              584      0               0  \n","213527           475              475      0               0  \n","282221           368              368      0               0  \n","24286            323              323      0               0  \n","44748            305              305      0               0  \n","126333           303              303      0               0  \n","29722            283              283      0               0  \n","284375           268              268      0               0  \n","43978            259              259      0               0  \n","265665           237              237      0               0  \n","175686           232              232      0               0  \n","23443            221              221      0               0  \n","74171            207              207      0               0  \n","125831           188              188      0               0  \n","158975           188              188      0               0  \n","\n","==================================================\n","     'ALMOST' REEL: THE 20 MOST IMPRESSIVE 'NEAR MISSES'\n","  (For 'Viral' tweets where the prediction was also 'Viral' or 'High')\n","==================================================\n","                                                                                                                                                                                                                                                                                                             Tweet Text  \\\n","105776                                                                                                                                                                                                                                                                                            FULL TIME <hyperlink>   \n","273880          CORY BOOKER DROPPED OUT\\n\\nAnother One Bites the Dust\\n\\nThe man known as bathroom booker and Spartacus dropped out the Presidential Race. \\n\\nI FORGOT HE WAS WAS IN THE RACE\\n\\nNot only I did I forget that I forgot he even existed \\n\\nWHO ELSE FORGOT OR AM I ALONE?\\n\\n#ByeByeBooker <hyperlink>   \n","115108                It‚Äôs a beautiful day for #BTS‚òÄÔ∏è Please remember to plan for cooler weather tonight and dress accordingly! \\n\\nIf you are picking up your child after the show, please arrive in the Pick Up Zone between 8:30 and 9:30pm. We appreciate your cooperation in advance! \\n\\n#BTSxMETLIFE <hyperlink>   \n","155163                                                                                                                                                                            #BTS #Jin shows us how you can zoom in to what you love with the #GalaxyS20 Series. \\nLearn about #SpaceZoom: <hyperlink> <hyperlink>   \n","109131                                 A MESSAGE FOR THE PRESIDENT \\n\\nWe see what you‚Äôre doing. \\nWe see how hard you‚Äôre working. \\nWe see how much you care.\\n&amp; We will remember in November what we saw.\\n\\nThank you President <mention> for being all about the American people since Day One.\\n\\n <hyperlink>   \n","7303                            After making this video yesterday Jemele Hills Goons have been threatening me because I don‚Äôt agree with her wanting segregation \\n\\nThey also claim she is fighting for the  rights &amp; freedom of black people.\\n\\nWe have Rights! We are Free!\\n#RacistJemeleHill \\n \\n<hyperlink>   \n","247624    .<mention> IS NO GOOD!\\n\\nA man called <mention> ‚ÄúMentally Retarded‚Äù &amp; she Laughed &amp; said  ‚ÄúWell Said‚Äù\\n\\nShe thinks Anti Disability slurs are funny &amp; now pretending to be sorry.\\n \\nShe‚Äôs another Hillary Clinton \\n\\nLet‚Äôs start calling her  Kamala Clinton \\n\\nüëâ #KamalaClinton <hyperlink>   \n","215204  I‚ÄôM DEVASTATED &amp; BROKEN\\n\\nI Didn‚Äôt get the Money I was Promised by <mention>.\\n\\nI need everyone to help me get this message to him &amp; the world.\\n\\nPlease Retweet or Comment using the Hashtag below so I can get my money \\n\\n useüëâ  #YangPayTerrenceKWilliams\\n               <mention> <hyperlink>   \n","64722                                                                                                                                                                                                                                                          üêê There's only one #Messi\\n\\n(IG: <mention>) <hyperlink>   \n","17691            DISGUSTING!\\n\\nA lot of Looney People are attacking President <mention> son Barron Trump. \\n\\n<mention> needs to do something about the Accounts that bully Children!\\n\\n*RT &amp; Please report any accounts bullying children. \\n\\nüëâ #LeaveBarronTrumpAlone\\n      #TwitterBanTheBullies <hyperlink>   \n","177671                         EVERYONE PLEASE TAKE THE TIME OUT TO TWEET OR COMMENT using hashtag  #ArrestGeorgeLopez \\n\\nHe said he will kill the President for 40 million dollars.\\n\\nTagging the <mention> <mention> <mention> \\n\\nCopy, Paste &amp; Tweet \\n#ArrestGeorgeLopez\\n#ArrestGeorgeLopez\\n\\n <hyperlink>   \n","30381                                                                                                                                                                       Tell all the skinny hoes to point me where the thick hoes at!! My new song feat <mention> #BIGBOOTY !! Out now on all platforms <hyperlink>   \n","298203                                                                                                                                                                                                                                                                                What‚Äôs up, Ousmane! üëä <hyperlink>   \n","252760                                                                                                                                                                                                                                                           He even gets IN THE MIDDLE of the rondo! ü§Ø <hyperlink>   \n","204681                                                                                                                                  This is why I couldn‚Äôt be a police officer! They have to put up with so much bull on a daily basis! \\n\\nThis is why I also have so much respect for law enforcement <hyperlink>   \n","277033                                 MY 3RD TIME POSTING THIS!\\n\\nI WANT EVERYONE TO KNOW WHAT THEY ARE DOING!\\n\\nWhat happened to freedom of speech? Supporting Trump is not a crime! DONT BAN ME!\\n\\nMy hashtag is being suppressed now-Use it as much as possible!\\n\\nüëâ #DontBanTerrenceKWilliams \\n \\n<hyperlink>   \n","219587                                                                                                                                                                                                    In two days, live your best life by swinging to your nearest theater for #SpiderManFarFromHome. üéâ <hyperlink>   \n","2718                                                                                                                                                                                            [#ÏïÑÏä§Ìä∏Î°ú #MJ]\\nüéÉHAPPY HALLOWEENüéÉ\\nTrick or treatüëªüíù\\n\\nCandy Please„Ä∞Ô∏èü§≤üç≠\\n\\n#ASTRO #AROHA #ÏïÑÎ°úÌïò\\n#Ìï†Î°úÏúà #Halloween <hyperlink>   \n","72787                                                                                                                                                                                                                      üêê Arguably the greatest goal in the history of goals | Leo #Messi | #Bar√ßaGetafe <hyperlink>   \n","16215                                                                                                                                                                                                                                                                               Yes, we know that song. <hyperlink>   \n","\n","        Actual Likes  Predicted Likes  Error  Absolute Error  \n","105776         23039            23044     -5               5  \n","273880         15114            15107      7               7  \n","115108         14494            14436     58              58  \n","155163         43666            43603     63              63  \n","109131         15243            15175     68              68  \n","7303           14701            14775    -74              74  \n","247624         13584            13485     99              99  \n","215204         13417            13289    128             128  \n","64722          22633            22430    203             203  \n","17691          15668            15939   -271             271  \n","177671         13501            13917   -416             416  \n","30381          14803            15229   -426             426  \n","298203         22598            22171    427             427  \n","252760         22658            22220    438             438  \n","204681         13872            14312   -440             440  \n","277033         15755            16207   -452             452  \n","219587         13041            13493   -452             452  \n","2718           19442            19927   -485             485  \n","72787          22329            22824   -495             495  \n","16215          17280            16613    667             667  \n"]}],"execution_count":null}]}